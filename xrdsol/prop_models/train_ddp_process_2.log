[2024-10-11 10:03:54,994][hydra.utils][INFO] - Instantiating <xrdsol.pl_data.datamodule.CrystDataModule>
[2024-10-11 10:03:55,750][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-10-11 10:03:55,750][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2024-10-11 10:04:17,101][hydra.utils][INFO] - Instantiating <xrdsol.pl_modules.diffusion.CSPDiffusion>
[2024-10-11 10:04:18,874][hydra.utils][INFO] - Passing scaler from datamodule to model <StandardScalerTorch(means: -1.219802737236023, stds: 1.0293837785720825)>
[2024-10-11 10:04:18,891][hydra.utils][INFO] - Adding callback <LearningRateMonitor>
[2024-10-11 10:04:18,892][hydra.utils][INFO] - Adding callback <EarlyStopping>
[2024-10-11 10:04:18,893][hydra.utils][INFO] - Adding callback <ModelCheckpoint>
[2024-10-11 10:04:18,895][hydra.utils][INFO] - Instantiating <WandbLogger>
[2024-10-11 10:04:18,898][hydra.utils][INFO] - W&B is now watching <{cfg.logging.wandb_watch.log}>!
[2024-10-11 10:04:18,928][hydra.utils][INFO] - Instantiating the Trainer
[2024-10-11 10:04:18,979][hydra.utils][INFO] - Starting training!
[2024-10-11 10:04:18,984][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
[2024-10-11 10:04:24,857][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for 4 nodes.
