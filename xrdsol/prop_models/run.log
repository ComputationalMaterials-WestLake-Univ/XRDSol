[2024-10-11 10:03:20,157][hydra.utils][INFO] - Instantiating <xrdsol.pl_data.datamodule.CrystDataModule>
[2024-10-11 10:03:20,897][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-10-11 10:03:20,898][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2024-10-11 10:03:37,070][hydra.utils][INFO] - Instantiating <xrdsol.pl_modules.diffusion.CSPDiffusion>
[2024-10-11 10:03:39,015][hydra.utils][INFO] - Passing scaler from datamodule to model <StandardScalerTorch(means: -1.219802737236023, stds: 1.0293837785720825)>
[2024-10-11 10:03:39,030][hydra.utils][INFO] - Adding callback <LearningRateMonitor>
[2024-10-11 10:03:39,030][hydra.utils][INFO] - Adding callback <EarlyStopping>
[2024-10-11 10:03:39,032][hydra.utils][INFO] - Adding callback <ModelCheckpoint>
[2024-10-11 10:03:39,038][hydra.utils][INFO] - Instantiating <WandbLogger>
[2024-10-11 10:03:39,040][hydra.utils][INFO] - W&B is now watching <{cfg.logging.wandb_watch.log}>!
[2024-10-11 10:03:49,981][hydra.utils][INFO] - Instantiating the Trainer
[2024-10-11 10:03:50,018][hydra.utils][INFO] - Starting training!
[2024-10-11 10:04:24,855][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2024-10-11 10:04:24,856][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for 4 nodes.
